{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.segmentation_dataset_loader import *\n",
    "from data.detection_dataset_loader import *\n",
    "from model import *\n",
    "from Trainer import *\n",
    "from evaluation.evaluate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.postprocessing.nms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_feed_dict(model, dataset, train_fusion_rgb, train_fusion_fv_lidar, anchor_values, use_nms):\n",
    "        # camera_tensor, lidar_tensor, fv_velo_tensor, label_tensor, Tr_velo_to_cam, R0_rect, P3, shift_h, shift_w = sess.run(dataset)\n",
    "        data = dataset.get_next(batch_size=1)\n",
    "\n",
    "#         for i in range(len(data)):\n",
    "#             data[i] = np.expand_dims(data[i], axis=0)\n",
    "        camera_tensor, lidar_tensor, label_tensor, Tr_velo_to_cam, R0_rect, P3, shift_h, shift_w = data\n",
    "#         print(np.max(camera_tensor))\n",
    "        d = {model.train_inputs_rgb: camera_tensor,\n",
    "                model.train_inputs_lidar: lidar_tensor,\n",
    "                model.Tr_velo_to_cam: Tr_velo_to_cam,\n",
    "                model.R0_rect: R0_rect,\n",
    "                model.P3: P3,\n",
    "                model.shift_h: shift_h,\n",
    "                model.shift_w: shift_w,\n",
    "                model.anchors: anchor_values,\n",
    "                model.use_nms: use_nms,\n",
    "                model.train_fusion_rgb: train_fusion_rgb,\n",
    "                model.is_training: False}\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return (1 / (1 + np.exp(-x.astype(np.float128)))).astype(np.float32)\n",
    "\n",
    "def convert_prediction_into_real_values(label_tensor, \n",
    "            anchors=np.array([3.9, 1.6, 1.5]), \n",
    "            input_size=(512, 448), output_size=(128, 112), is_label=False, th=0.5):\n",
    "\n",
    "    ratio = input_size[0] // output_size[0]\n",
    "    result = []\n",
    "    ones_index = np.where(sigmoid(label_tensor[:, :, :, -1])>=th)\n",
    "    if len(ones_index) > 0 and len(ones_index[0]) > 0:\n",
    "        for i in range(0, len(ones_index[0]), 1):\n",
    "            x = ones_index[0][i]\n",
    "            y = ones_index[1][i]\n",
    "            \n",
    "            out = np.copy(label_tensor[ones_index[0][i], ones_index[1][i], ones_index[2][i], :])\n",
    "            anchor = np.array([x+0.5, y+0.5, 0.5, anchors[0], anchors[1], anchors[2]])\n",
    "#             if not is_label:\n",
    "#               out[:3] = sigmoid(out[:3])\n",
    "            out[:3] = np.tanh(out[:3])*0.5 * anchor[3:6] + anchor[:3]\n",
    "            \n",
    "            out[:2] = out[:2] * ratio\n",
    "            out[2] = out[2] * 40\n",
    "            \n",
    "            out[3:6] = np.square(np.maximum(0, out[3:6])) * anchors\n",
    "            \n",
    "            k = ones_index[2][i]\n",
    "            if not is_label:\n",
    "              out[6] = sigmoid(out[6]) * np.pi/2 - np.pi/4\n",
    "            if k == 0 and out[6] < 0:\n",
    "                out[6] = out[6] + np.pi\n",
    "                \n",
    "            out[6] = out[6] + k * (np.pi/2)\n",
    "                        \n",
    "            result.append(out)\n",
    "            \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(converted_points, calib_path, \n",
    "                x_range=(0, 71), y_range=(-40, 40), z_range=(-3.0, 1), \n",
    "                size=(512, 448, 40), th=0.5):\n",
    "    all_result = []\n",
    "    for converted_points_ in converted_points:\n",
    "        if sigmoid(converted_points_[-1]) >= th:\n",
    "#              and sigmoid(converted_points_[8]) < th2\n",
    "            result = [0] * 16\n",
    "            result[0] = 'Car'\n",
    "            result[1] = -1\n",
    "            result[2] = -1\n",
    "            result[3] = -10\n",
    "            result[8] = converted_points_[5]\n",
    "            result[9] = converted_points_[4]\n",
    "            result[10] = converted_points_[3]\n",
    "            result[14] = converted_points_[6]\n",
    "            result[15] = sigmoid(converted_points_[-1])\n",
    "\n",
    "            calib_data = read_calib(calib_path)\n",
    "\n",
    "            # x_range=(0, 70)\n",
    "            # y_range=(-40, 40)\n",
    "            # z_range=(-2.5, 1)\n",
    "\n",
    "            x_size = (x_range[1] - x_range[0])\n",
    "            y_size = (y_range[1] - y_range[0])\n",
    "            z_size = (z_range[1] - z_range[0])\n",
    "\n",
    "            x_fac = (size[0]-1) / x_size\n",
    "            y_fac = (size[1]-1) / y_size\n",
    "            z_fac = (size[2]-1) / z_size\n",
    "\n",
    "            x, y, z = -((converted_points_[:3] - size) / np.array([x_fac, y_fac, z_fac])) - np.array([0, -1*y_range[0], -1*z_range[0]]) \n",
    "            point = np.array([[x, y, z]])\n",
    "            box3d_pts_3d = point\n",
    "\n",
    "            pts_3d_ref = project_velo_to_ref(box3d_pts_3d, calib_data['Tr_velo_to_cam'].reshape((3, 4)))\n",
    "            pts_3d_ref = project_ref_to_rect(pts_3d_ref, calib_data['R0_rect'].reshape((3, 3)))[0]\n",
    "            for k in range(3):\n",
    "                result[11 + k] = pts_3d_ref[k]\n",
    "\n",
    "            imgbbox = ProjectTo2Dbbox(pts_3d_ref, converted_points_[5], converted_points_[4],\n",
    "                         converted_points_[3], converted_points_[6], calib_data['P2'].reshape((3, 4)))\n",
    "\n",
    "            result[4:8] = imgbbox\n",
    "            all_result.append(result)\n",
    "    return all_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label2(label_path, calib_path, shift_h, shift_w, x_range=(0, 71), y_range=(-40, 40), z_range=(-3.0, 1), \n",
    "                    size=(512, 448, 40), get_actual_dims=False, from_file=True, translate_x=0, translate_y=0, ang=0, get_neg=False):\n",
    "#     return __read_label(label_path, calib_path, shift_h, shift_w, x_range=x_range, y_range=y_range, z_range=z_range, \n",
    "#                     size=size, get_actual_dims=get_actual_dims, from_file=from_file, translate_x=translate_x, translate_y=translate_y, ang=ang, get_neg=get_neg)\n",
    "\n",
    "\n",
    "\n",
    "# def __read_label(label_path, calib_path, shift_h, shift_w, x_range=(0, 71), y_range=(-40, 40), z_range=(-3.0, 1), \n",
    "#                     size=(512, 448, 32), get_actual_dims=False, from_file=True, translate_x=0, translate_y=0, ang=0,\n",
    "#                     get_neg=False):\n",
    "    \"\"\"\n",
    "    the file format is as follows: \n",
    "    type, truncated, occluded, alpha, bbox_left, bbox_top, bbox_right, bbox_bottom,\n",
    "    dimensions_height, dimensions_width, dimensions_length, location_x, location_y, location_z,\n",
    "    rotation_y, score) \n",
    "    \"\"\"\n",
    "    if from_file:\n",
    "        lines = []\n",
    "        with open(label_path) as label_file:\n",
    "            lines = label_file.readlines()\n",
    "    else:\n",
    "        lines = label_path.split('\\n')\n",
    "    # filter car class\n",
    "    lines = list(map(lambda x: x.split(), lines))\n",
    "    if len(lines) > 0:\n",
    "        if get_neg:\n",
    "            lines = list(filter(lambda x: len(x) > 0 and ( x[0] not in ['Car', 'Van', 'Truck', 'Tram', 'DontCare']), lines))\n",
    "            if len(lines) > 0:\n",
    "                lines = lines[:1]\n",
    "        else:\n",
    "            lines = list(filter(lambda x: len(x) > 0 and ( x[0] in ['Car', 'Van', 'Truck', 'Tram']), lines))\n",
    "    \n",
    "    def get_parameter(index):\n",
    "        return list(map(lambda x: x[index], lines))\n",
    "    \n",
    "    classes = get_parameter(0)\n",
    "    dimension_height = np.array(get_parameter(8)).astype(float)\n",
    "    dimension_width = np.array(get_parameter(9)).astype(float)\n",
    "    dimension_length = np.array(get_parameter(10)).astype(float)\n",
    "    # TODO: take shift into consideration - URGENT\n",
    "    location_x = np.array(get_parameter(11)).astype(float)\n",
    "    location_y = np.array(get_parameter(12)).astype(float)\n",
    "    location_z = np.array(get_parameter(13)).astype(float)\n",
    "    angles = np.array(get_parameter(14)).astype(float)\n",
    "    \n",
    "    # print(len(classes))\n",
    "    calib_data = read_calib(calib_path)\n",
    "\n",
    "    locations = np.array([[location_x[i], location_y[i], location_z[i]] for i in range(len(classes))])\n",
    "    # print(locations)\n",
    "    if len(locations) > 0 and len(locations[0]) > 0:\n",
    "        locations = project_rect_to_velo(locations, calib_data['R0_rect'].reshape((3, 3)), calib_data['Tr_velo_to_cam'].reshape((3, 4)))\n",
    "    # print(z_range)\n",
    "    indxes = np.array(list(map(lambda point: (point[0] >= x_range[0]  and point[0] <= x_range[1])\n",
    "                                    and (point[1] >= y_range[0] and point[1] <= y_range[1])\n",
    "                                    and (point[2] >= z_range[0] and point[2] <= z_range[1]) , locations)))\n",
    "\n",
    "    locations = np.array(list(filter(lambda point: (point[0] >= x_range[0]  and point[0] <= x_range[1])\n",
    "                                    and (point[1] >= y_range[0] and point[1] <= y_range[1])\n",
    "                                    and (point[2] >= z_range[0] and point[2] <= z_range[1]) , locations)))\n",
    "\n",
    "    if len(locations) > 0:\n",
    "        locations[:, :2] = locations[:, :2] - np.array([translate_x, translate_y])\n",
    "\n",
    "    # print('.......')\n",
    "    \n",
    "\n",
    "    points = [project_point_from_camera_coor_to_velo_coor([location_x[i], location_y[i], location_z[i]], \n",
    "                                                        [dimension_height[i], dimension_width[i], dimension_length[i]],\n",
    "                                                        angles[i],\n",
    "                                                         calib_data)\n",
    "                for i in range(len(locations))]\n",
    "    \n",
    "    x_size = (x_range[1] - x_range[0])\n",
    "    y_size = (y_range[1] - y_range[0])\n",
    "    z_size = (z_range[1] - z_range[0])\n",
    "            \n",
    "    x_fac = (size[0]-1) / x_size\n",
    "    y_fac = (size[1]-1) / y_size\n",
    "    z_fac = (size[2]-1) / z_size\n",
    "    if get_actual_dims:\n",
    "        import math\n",
    "        for i in range(len(points)):\n",
    "            b = points[i]\n",
    "            x0 = b[0][0]\n",
    "            y0 = b[0][1]\n",
    "            x1 = b[1][0]\n",
    "            y1 = b[1][1]\n",
    "            x2 = b[2][0]\n",
    "            y2 = b[2][1]\n",
    "            u0 = -(x0) * x_fac + size[0]\n",
    "            v0 = -(y0 + 40) * y_fac + size[1]\n",
    "            u1 = -(x1) * x_fac + size[0]\n",
    "            v1 = -(y1 + 40) * y_fac + size[1]\n",
    "            u2 = -(x2) * x_fac + size[0]\n",
    "            v2 = -(y2 + 40) * y_fac + size[1]\n",
    "            # print(dimension_length[i])\n",
    "            dimension_length[i] = math.sqrt((v1-v2)**2 + (u1-u2)**2)\n",
    "            # print(dimension_length[i])\n",
    "            dimension_width[i] = math.sqrt((v1-v0)**2 + (u1-u0)**2)\n",
    "            # print(dimension_height[i])\n",
    "            dimension_height[i] = math.sqrt((-(b[0][2]+(-1*z_range[1]))*z_fac-(-b[4][2]+z_range[1])*z_fac)**2)\n",
    "            # print(dimension_height[i])\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "    x_range = (x_range[0] + translate_x, x_range[1] + translate_x)\n",
    "    y_range = (y_range[0] + translate_y, y_range[1] + translate_y)\n",
    "    output = [[-(locations[i][0]) * x_fac + size[0], -(locations[i][1] + -1*y_range[0]) * y_fac + size[1], -(locations[i][2] + -1*z_range[0]) * z_fac + size[2], \n",
    "                dimension_height[i], dimension_width[i], dimension_length[i], angles[i]] \n",
    "                for i in range(len(locations))]\n",
    "    # import math\n",
    "    if ang != 0:\n",
    "        for i in range(len(locations)):\n",
    "            w = size[0]\n",
    "            h = size[1]\n",
    "            output[i][0], output[i][1] = rotate2((w//2, h//2), (output[i][0], output[i][1]), ang / 57.2958)\n",
    "            output[i][6] = output[i][6] - ang / 57.2958\n",
    "\n",
    "    output = np.array(output)\n",
    "    if from_file:\n",
    "        return points, output, calib_data['Tr_velo_to_cam'], calib_data['R0_rect'], calib_data['P2']\n",
    "    else:\n",
    "        return output, indxes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label2(label_path, calib_path, shift_h, shift_w, x_range=(0, 71), y_range=(-40, 40), z_range=(-3.0, 1), \n",
    "                    size=(512, 448, 40), get_actual_dims=False, from_file=True, translate_x=0, translate_y=0, translate_z=0, ang=0, get_neg=False):\n",
    "\n",
    "    \"\"\"\n",
    "    the file format is as follows: \n",
    "    type, truncated, occluded, alpha, bbox_left, bbox_top, bbox_right, bbox_bottom,\n",
    "    dimensions_height, dimensions_width, dimensions_length, location_x, location_y, location_z,\n",
    "    rotation_y, score) \n",
    "    \"\"\"\n",
    "    if from_file:\n",
    "        lines = []\n",
    "        with open(label_path) as label_file:\n",
    "            lines = label_file.readlines()\n",
    "    else:\n",
    "        lines = label_path.split('\\n')\n",
    "#     print(len(lines))\n",
    "    # filter car class\n",
    "    lines = list(map(lambda x: x.split(), lines))\n",
    "    if len(lines) > 0:\n",
    "        if get_neg:\n",
    "            lines = list(filter(lambda x: len(x) > 0 and ( x[0] not in ['Car', 'Van', 'Truck', 'Tram', 'DontCare']), lines))\n",
    "            if len(lines) > 0:\n",
    "                lines = lines[:1]\n",
    "        else:\n",
    "            lines = list(filter(lambda x: len(x) > 0 and ( x[0] in ['Car', 'Van', 'Truck', 'Tram']), lines))\n",
    "    \n",
    "    def get_parameter(index):\n",
    "        return list(map(lambda x: x[index], lines))\n",
    "    \n",
    "    classes = np.array(get_parameter(0))\n",
    "    dimension_height = np.array(get_parameter(8)).astype(float)\n",
    "    dimension_width = np.array(get_parameter(9)).astype(float)\n",
    "    dimension_length = np.array(get_parameter(10)).astype(float)\n",
    "    # TODO: take shift into consideration - URGENT\n",
    "    location_x = np.array(get_parameter(11)).astype(float)\n",
    "    location_y = np.array(get_parameter(12)).astype(float)\n",
    "    location_z = np.array(get_parameter(13)).astype(float)\n",
    "    angles = np.array(get_parameter(14)).astype(float)\n",
    "    directions = np.array(angles>= 0).astype(float)\n",
    "    \n",
    "    # print(len(classes))\n",
    "    calib_data = read_calib(calib_path)\n",
    "\n",
    "    locations = np.array([[location_x[i], location_y[i], location_z[i]] for i in range(len(classes))])\n",
    "\n",
    "    if len(locations) > 0 and len(locations[0]) > 0:\n",
    "        locations = project_rect_to_velo(locations, calib_data['R0_rect'].reshape((3, 3)), calib_data['Tr_velo_to_cam'].reshape((3, 4)))\n",
    "#     print(len(locations))\n",
    "    # print(z_range)\n",
    "\n",
    "    indx = []\n",
    "    i = 0\n",
    "    for point in locations:\n",
    "        if (point[0] >= x_range[0]  and point[0] <= x_range[1])\\\n",
    "            and (point[1] >= y_range[0] and point[1] <= y_range[1])\\\n",
    "            and (point[2] >= z_range[0] and point[2] <= z_range[1]):\n",
    "            indx.append(i)\n",
    "        i += 1\n",
    "\n",
    "    indxes = np.array(list(map(lambda point: (point[0] >= x_range[0]  and point[0] <= x_range[1])\n",
    "                                    and (point[1] >= y_range[0] and point[1] <= y_range[1])\n",
    "                                    and (point[2] >= z_range[0] and point[2] <= z_range[1]) , locations)))\n",
    "    locations = np.array(list(filter(lambda point: (point[0] >= x_range[0]  and point[0] <= x_range[1])\n",
    "                                    and (point[1] >= y_range[0] and point[1] <= y_range[1])\n",
    "                                    and (point[2] >= z_range[0] and point[2] <= z_range[1]) , locations)))\n",
    "\n",
    "    if len(indx) > 0:\n",
    "        dimension_height = dimension_height[indx]\n",
    "        dimension_width = dimension_width[indx]\n",
    "        dimension_length = dimension_length[indx]\n",
    "        location_x = location_x[indx]\n",
    "        location_y = location_y[indx]\n",
    "        location_z = location_z[indx]\n",
    "        angles = angles[indx]\n",
    "        classes = classes[indx]\n",
    "        directions = directions[indx]\n",
    "\n",
    "    if len(locations) > 0:\n",
    "        locations[:, :3] = locations[:, :3] - np.array([translate_x, translate_y, -translate_z])\n",
    "\n",
    "    # print('.......')\n",
    "    # print(len(locations))\n",
    "\n",
    "    points = [project_point_from_camera_coor_to_velo_coor([location_x[i], location_y[i], location_z[i]], \n",
    "                                                        [dimension_height[i], dimension_width[i], dimension_length[i]],\n",
    "                                                        angles[i],\n",
    "                                                         calib_data)\n",
    "                for i in range(len(locations))]\n",
    "    \n",
    "    x_size = (x_range[1] - x_range[0])\n",
    "    y_size = (y_range[1] - y_range[0])\n",
    "    z_size = (z_range[1] - z_range[0])\n",
    "            \n",
    "    x_fac = (size[0]-1) / x_size\n",
    "    y_fac = (size[1]-1) / y_size\n",
    "    z_fac = (size[2]-1) / z_size\n",
    "    if get_actual_dims:\n",
    "        import math\n",
    "        for i in range(len(points)):\n",
    "            b = points[i]\n",
    "            x0 = b[0][0]\n",
    "            y0 = b[0][1]\n",
    "            x1 = b[1][0]\n",
    "            y1 = b[1][1]\n",
    "            x2 = b[2][0]\n",
    "            y2 = b[2][1]\n",
    "            u0 = -(x0) * x_fac + size[0]\n",
    "            v0 = -(y0 + 40) * y_fac + size[1]\n",
    "            u1 = -(x1) * x_fac + size[0]\n",
    "            v1 = -(y1 + 40) * y_fac + size[1]\n",
    "            u2 = -(x2) * x_fac + size[0]\n",
    "            v2 = -(y2 + 40) * y_fac + size[1]\n",
    "            dimension_length[i] = math.sqrt((v1-v2)**2 + (u1-u2)**2)\n",
    "            dimension_width[i] = math.sqrt((v1-v0)**2 + (u1-u0)**2)\n",
    "            dimension_height[i] = math.sqrt((-(b[0][2]+(-1*z_range[1]))*z_fac-(-b[4][2]+z_range[1])*z_fac)**2)\n",
    "\n",
    "      \n",
    "    for i in range(len(locations)):\n",
    "        if angles[i] < 0:\n",
    "            angles[i] += 3.14\n",
    "\n",
    "    x_range = (x_range[0] + translate_x, x_range[1] + translate_x)\n",
    "    y_range = (y_range[0] + translate_y, y_range[1] + translate_y)\n",
    "    z_range = (z_range[0] + translate_z, z_range[1] + translate_z)\n",
    "    output = [[-(locations[i][0] + -1*x_range[0]) * x_fac + size[0], -(locations[i][1] + -1*y_range[0]) * y_fac + size[1], -(locations[i][2] + -1*z_range[0]) * z_fac + size[2], \n",
    "                dimension_length[i], dimension_width[i], dimension_height[i], angles[i]] \n",
    "                for i in range(len(locations))]\n",
    "    # import math\n",
    "    if ang != 0:\n",
    "        for i in range(len(locations)):\n",
    "            w = size[0]\n",
    "            h = size[1]\n",
    "            output[i][0], output[i][1] = rotate2((w//2, h//2), (output[i][0], output[i][1]), ang / 57.2958)\n",
    "            output[i][6] = output[i][6] - ang / 57.2958\n",
    "\n",
    "    output = list(filter(lambda point: 0 <= point[0] < size[0] and 0 <= point[1] < size[1] and 0 <= point[2] < size[2] , output))\n",
    "    output = np.array(output)\n",
    "\n",
    "    if from_file:\n",
    "        return points, output, calib_data['Tr_velo_to_cam'], calib_data['R0_rect'], calib_data['P2'], directions\n",
    "    else:\n",
    "        return output, indxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(final_output, th, new_file_path, apply_nms=False, sess=None):\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    converted_points = convert_prediction_into_real_values(final_output[0, :, :, :, :], th=th)\n",
    "    points = get_points(converted_points, base_path + '/data_object_calib/training/calib/'+ current_file + '.txt', th=th)\n",
    "#     print(len(points))\n",
    "    res = '\\n'.join([' '.join([str(l) for l in points[i]]) for i in range(len(points))])\n",
    "#     with tf.device('/device:CPU:0'):\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    if apply_nms:\n",
    "            labels, indxes = read_label2(res, base_path + '/data_object_calib/training/calib/'+ current_file + '.txt', 0, 0, get_actual_dims=True, from_file=False)\n",
    "#             if len(labels) != len(points):\n",
    "#                 print('not the same', new_file_path)\n",
    "    #             return\n",
    "            points = np.array(points)\n",
    "            \n",
    "            if len(labels) > 0:\n",
    "                points = points[indxes]\n",
    "                selected_idx = nms(labels, np.array([points[i][-1] for i in range(len(points))]), max_output_size=100, iou_threshold=0.3, sess=sess)\n",
    "            else:\n",
    "                selected_idx = []\n",
    "\n",
    "            if len(selected_idx) > 0:\n",
    "                points = points[selected_idx]\n",
    "                res = '\\n'.join([' '.join([str(l) for l in points[i]]) for i in range(len(points))])\n",
    "            else:\n",
    "                res=\"\"\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    text_file = open(new_file_path, \"wb+\")\n",
    "    text_file.write(res.encode())\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms2(label, scores, max_output_size=100, iou_threshold=0.1, sess=None):\n",
    "    boxes = []\n",
    "\n",
    "    for j in range(0, len(label)):\n",
    "\n",
    "        w = label[j][3]\n",
    "        h = label[j][4] \n",
    "        x = label[j][0]\n",
    "        y = label[j][1]\n",
    "        a = label[j][6]\n",
    "        \n",
    "\n",
    "        polygon = convert5Pointto8Point(y, x, w, h, -a*57.2958)\n",
    "        xs = polygon[0::2]\n",
    "        ys = polygon[1::2]\n",
    "            \n",
    "        boxes.append([xs[0], ys[0], xs[2], ys[2]])\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    with tf.Graph().as_default():\n",
    "        selected_indices = tf.image.non_max_suppression(\n",
    "                    boxes, scores, max_output_size=max_output_size, iou_threshold=iou_threshold)\n",
    "        if sess is not None:\n",
    "            selected_indices = sess.run(selected_indices)\n",
    "        else:\n",
    "            with tf.Session() as sess:\n",
    "                selected_indices = sess.run(selected_indices)\n",
    "\n",
    "    return selected_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions2(th, new_file_path, old_file_path, apply_nms=False, sess=None):\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    \n",
    "    res = []\n",
    "    with open(old_file_path) as label_file:\n",
    "            res = label_file.readlines()\n",
    "    res = ''.join(res)\n",
    "    points2 = res.split('\\n')\n",
    "    points = []\n",
    "    for i in range(len(points2)):\n",
    "        temp = []\n",
    "        temp = points2[i].split(' ')\n",
    "        points.append(temp)\n",
    "#     print(points.split('\\n')[0])\n",
    "    \n",
    "#     converted_points = convert_prediction_into_real_values(final_output[0, :, :, :, :], th=th)\n",
    "#     points = get_points(converted_points, base_path + '/data_object_calib/training/calib/'+ current_file + '.txt', th=th)\n",
    "#     print(len(points))\n",
    "#     res = '\\n'.join([' '.join([str(l) for l in points[i]]) for i in range(len(points))])\n",
    "#     with tf.device('/device:CPU:0'):\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    if apply_nms:\n",
    "            labels, indxes = read_label2(res, base_path + '/data_object_calib/training/calib/'+ current_file + '.txt', 0, 0, get_actual_dims=True, from_file=False)\n",
    "#             if len(labels) != len(points):\n",
    "#                 print('not the same', new_file_path, len(labels), len(points))\n",
    "    #             return\n",
    "            points = np.array(points)\n",
    "            \n",
    "            if len(labels) > 0:\n",
    "                points = points[indxes]\n",
    "                selected_idx = nms2(labels, np.array([points[i][-1] for i in range(len(points))]), max_output_size=100, iou_threshold=0.3, sess=sess)\n",
    "            else:\n",
    "                selected_idx = []\n",
    "\n",
    "            if len(selected_idx) > 0:\n",
    "                points = points[selected_idx]\n",
    "                res = '\\n'.join([' '.join([str(l) for l in points[i]]) for i in range(len(points))])\n",
    "            else:\n",
    "                res=\"\"\n",
    "#     now = datetime.now()\n",
    "#     current_time = now.strftime(\"%H:%M:%S\")\n",
    "#     print(\"Current Time =\", current_time)\n",
    "    text_file = open(new_file_path, \"wb+\")\n",
    "    text_file.write(res.encode())\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/injy/mariam_workspace/env3/lib/python3.5/site-packages/torch/hub.py:411: UserWarning: TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead\n",
      "  warnings.warn('TORCH_MODEL_ZOO is deprecated, please use env TORCH_HOME instead')\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'fusion': False\n",
    "}\n",
    "model = Model(graph=None, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../../../Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = list(map(lambda x: x.split('.')[0], os.listdir(base_path+'/data_object_image_3/training/image_3')))\n",
    "random.seed(0)\n",
    "random.shuffle(list_files)\n",
    "ln = int(len(list_files) * 0.5)\n",
    "list_files= list_files[ln:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['005691', '005574', '002151']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'predictions_uncertainity_epochs_30_best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../prediction_files/predictions_uncertainity_epochs_30_best': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls \"../prediction_files/\"\"$dir_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '../prediction_files/predictions_uncertainity_epochs_30_best': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r \"../prediction_files/\"\"$dir_name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir \"../prediction_files/\"\"$dir_name\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th05_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th05_2/data\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th10_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th10_2/data\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th20_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th20_2/data\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th30_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th30_2/data\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th40_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th40_2/data\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th50_2\"\n",
    "!mkdir \"../prediction_files/\"\"$dir_name\"\"/bev/th50_2/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../training_files/tmp_best2/model.ckpt-213180\n",
      "i =  100\n",
      "i =  200\n",
      "i =  300\n",
      "i =  400\n",
      "i =  500\n",
      "i =  600\n",
      "i =  700\n",
      "i =  800\n",
      "i =  900\n",
      "i =  1000\n",
      "i =  1100\n",
      "i =  1200\n",
      "i =  1300\n",
      "i =  1400\n",
      "i =  1500\n",
      "i =  1600\n",
      "i =  1700\n",
      "i =  1800\n",
      "i =  1900\n",
      "i =  2000\n",
      "i =  2100\n",
      "i =  2200\n",
      "i =  2300\n",
      "i =  2400\n",
      "i =  2500\n",
      "i =  2600\n",
      "i =  2700\n",
      "i =  2800\n",
      "i =  2900\n",
      "i =  3000\n",
      "i =  3100\n",
      "i =  3200\n",
      "i =  3300\n",
      "i =  3400\n",
      "i =  3500\n",
      "i =  3600\n",
      "i =  3700\n"
     ]
    }
   ],
   "source": [
    "with model.graph.as_default():\n",
    "            \n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "\n",
    "  with tf.Session(config=config) as sess:\n",
    "    model.saver.restore(sess, tf.train.latest_checkpoint('../training_files/tmp_best2/'))\n",
    "\n",
    "    anchor_values = prepare_anchors()\n",
    "    anchor_values = np.repeat(anchor_values, 1, axis=0)\n",
    "    dataset = DetectionDatasetLoader(base_path='../../../Data', training_per=0.5, batch_size=1, random_seed=0, training=False)\n",
    "   \n",
    "    cls_losses = []\n",
    "    reg_losses = []\n",
    "    total_losses = []\n",
    "    i = 0\n",
    "    \n",
    "    apply_nms=False\n",
    "    \n",
    "    try:    \n",
    "        while True:\n",
    "            feed_dict = prepare_dataset_feed_dict(model, dataset, False, False, anchor_values, False)\n",
    "\n",
    "            final_output= sess.run(model.final_output, feed_dict=feed_dict)\n",
    "\n",
    "            if i < len(list_files):\n",
    "                current_file = list_files[i]\n",
    "                \n",
    "                th = 0.05\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th05_2/data/' + current_file + '.txt'\n",
    "                write_predictions(final_output, th, new_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "                th = 0.10\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th10_2/data/' + current_file + '.txt'\n",
    "                write_predictions(final_output, th, new_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "                th = 0.20\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th20_2/data/' + current_file + '.txt'\n",
    "                write_predictions(final_output, th, new_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "                th = 0.30\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th30_2/data/' + current_file + '.txt'\n",
    "                write_predictions(final_output, th, new_file_path, apply_nms=apply_nms)\n",
    "                \n",
    "#                 th = 0.40\n",
    "#                 new_file_path = '../prediction_files/' + dir_name + '/bev/th40_2/data/' + current_file + '.txt'\n",
    "#                 write_predictions(final_output, th, new_file_path, apply_nms=apply_nms)\n",
    "                \n",
    "#                 th = 0.50\n",
    "#                 new_file_path = '../prediction_files/' + dir_name + '/bev/th50_2/data/' + current_file + '.txt'\n",
    "#                 write_predictions(final_output, th, new_file_path, apply_nms=apply_nms)\n",
    "\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print('i = ', i)\n",
    "#             break\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b8cce9835206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mold_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../prediction_files/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mold_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/bev/th30_2/data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mnew_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../prediction_files/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdir_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/bev/th30_2/data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mwrite_predictions2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_nms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_nms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-d6e5255da4f1>\u001b[0m in \u001b[0;36mwrite_predictions2\u001b[0;34m(th, new_file_path, old_file_path, apply_nms, sess)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindxes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mselected_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_output_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mselected_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/Object-Detection-3D-master/src/data/postprocessing/nms.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(label, scores, max_output_size, iou_threshold, sess)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 boxes, scores, max_output_size=max_output_size, iou_threshold=iou_threshold)\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mselected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/mariam_workspace/env3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_name = 'predictions_uncertainity_epochs_30_nms'\n",
    "old_dir = 'predictions_uncertainity_epochs_30'\n",
    "if True:\n",
    "            \n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allow_growth = True\n",
    "\n",
    "  with tf.Session(config=config) as sess:\n",
    "\n",
    "    cls_losses = []\n",
    "    reg_losses = []\n",
    "    total_losses = []\n",
    "    i = 0\n",
    "    \n",
    "    apply_nms=True\n",
    "    \n",
    "    try:    \n",
    "        while True:\n",
    "\n",
    "            if i < len(list_files):\n",
    "                current_file = list_files[i]\n",
    "                \n",
    "                th = 0.10\n",
    "                old_file_path = '../prediction_files/' + old_dir + '/bev/th10_2/data/' + current_file + '.txt'\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th10_2/data/' + current_file + '.txt'\n",
    "                write_predictions2(th, new_file_path, old_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "                th = 0.20\n",
    "                old_file_path = '../prediction_files/' + old_dir + '/bev/th10_2/data/' + current_file + '.txt'\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th20_2/data/' + current_file + '.txt'\n",
    "                write_predictions2(th, new_file_path, old_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "                th = 0.30\n",
    "                old_file_path = '../prediction_files/' + old_dir + '/bev/th30_2/data/' + current_file + '.txt'\n",
    "                new_file_path = '../prediction_files/' + dir_name + '/bev/th30_2/data/' + current_file + '.txt'\n",
    "                write_predictions2(th, new_file_path, old_file_path, apply_nms=apply_nms, sess=sess)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "            if i % 100 == 0:\n",
    "                print('i = ', i)\n",
    "#             break\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        pass\n",
    "    except StopIteration:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['001966', '003202', '005344', '001177', '000534', '002694', '004495',\\\n",
    "          '001334', '000611', '007052', '001813', '000195', '004809', '000620',\\\n",
    "          '000803', '004562', '002591', '003033', '001587', '005985', '006109',\\\n",
    "          '004775']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['001966', '003202', '005344', '001177', '000534', '002694', '004495', '001334',\\\n",
    " '000611', '007052', '001813', '000195', '004809', '000620', '000803', '004562',\\\n",
    " '002591', '003033', '005985', '006109', '004775']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
